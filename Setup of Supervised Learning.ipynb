{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup of Supervised Learning Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4CAF50; border-radius: 8px; padding: 10px; background-color: #e8f5e9; color: #2e7d32;\">\n",
    "<b>Goal</b> <br>\n",
    "Given labeled examples, find the  <b>prediction</b> of an unlabeled example\n",
    "</div><br><br>\n",
    "\n",
    "---\n",
    "\n",
    "| **Applications: Examples**                | **Task Description**                                                                                                                                        | **Traditional Approach**                                                                                                                    | **Machine Learning Approach**                                                                                          |\n",
    "|--------------------------------|--------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------------------------------------------------------------------------------------------------------------------------------------|-----------------------------------------------------------------------------------------------------------------------|\n",
    "| **Email Spam Filtering**       | <span style=\"color:blue;\">Classify an email as spam or not-spam.</span>                                                                                      | - Write manual rules to classify emails. <br> **Drawbacks**: <br> &emsp; - Rules need constant updates. <br> &emsp; - Vulnerable to spammersâ€™ tricks. <br> &emsp; - Limited generalizability across languages. | - Learn a classifier from historical data (e.g., user-labeled spam vs. not-spam emails).                              |\n",
    "| **Web-Search Ranking**         | <span style=\"color:blue;\">Predict which webpage a user will click based on their query.</span>                                                               | - Rank pages manually or use heuristic-based rules.                                                                                         | - Predict user behavior and preferences by training on historical click-through data.                                 |\n",
    "| **Online Advertisement Placement** | <span style=\"color:blue;\">Predict ad revenue based on user behavior.</span>                                                                                   | - Assign advertisements based on static rules or predefined criteria.                                                                      | - Predict ad revenue by learning from user profiles, browsing history, and past ad performance.                       |\n",
    "| **Visual Object Recognition**  | <span style=\"color:blue;\">Predict objects in an image (e.g., for self-driving cars).</span>                                                                  | - Manually define features or rules for detecting objects.                                                                                  | - Learn features directly from labeled image datasets (e.g., car, pedestrian, traffic signs).                         |\n",
    "| **Face Detection**             | <span style=\"color:blue;\">Detect if an image patch contains a human face.</span>                                                                             | - Use manually defined geometric rules (e.g., ratios of facial features).                                                                   | - Automatically detect faces by training on labeled face/non-face image datasets.                                     |\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"border: 2px solid #4CAF50; border-radius: 8px; padding: 10px; background-color: #e8f5e9; color: #2e7d32;\">\n",
    "<b>Training Data</b> <br>\n",
    "\n",
    "\n",
    "Training data consists of **pairs** of inputs $(\\mathbf{x}, y)$:\n",
    "- $\\mathbf{x} \\in \\textcolor{blue}{\\mathbb{R}^d}$: **Features(Input)**.\n",
    "- $y$:                **Label (Output)**.\n",
    "\n",
    "  \n",
    "The training data is denoted as:\n",
    "$$\n",
    "D = \\{\\textcolor{teal}{(\\mathbf{x}_1, y_1)}, \\ldots, \\textcolor{teal}{(\\mathbf{x}_n, y_n)}\\} \\subseteq \\textcolor{blue}{\\mathbb{R}^d} \\times \\textcolor{purple}{\\mathcal{C}}\n",
    "$$\n",
    "\n",
    "- $\\mathbf{x}$: The **features** (input variables) that describe each data instance.\n",
    "- $y$: The **output** or label associated with each data instance.\n",
    "- $\\mathbb{R}^d$: The **$d$-dimensional feature space**, where each feature vector $\\mathbf{x} \\in \\mathbb{R}^d$ resides.\n",
    "- $\\mathcal{C}$: The **label space**, which represents the set of possible output labels.\n",
    "- $\\subseteq$: The **subset or identical set** notation. If $A \\subseteq B$, it indicates that every element of set $A$ is also an element of set $B$, or $A$ is identical to $B$.\n",
    "</div><br><br>\n",
    "\n",
    "\n",
    "\n",
    "<div style=\"border: 1px solid #ff4d4d; background-color: #ffe6e6; padding: 10px; border-radius: 5px; font-size: 14px;\">\n",
    "  <b style=\"color: #cc0000;\">Why Training Data Should Be Obtained from the Same Distribution as Deployment Data?</b>\n",
    "  <p>\n",
    "    If training data does not match the deployment data distribution, the model will fail to generalize and perform poorly in real-world scenarios.\n",
    "  </p>\n",
    "  <b>Example:</b>\n",
    "  <p>\n",
    "    Nokia's face recognition system trained primarily on European facial data struggled to recognize faces from Asian and African demographics when deployed globally. This mismatch in data distributions led to biased and inaccurate results, highlighting the importance of aligning training data with the intended deployment environment.\n",
    "  </p>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "<br><br>\n",
    "\n",
    "\n",
    "<div style=\"border: 1px solid #add8e6; background-color: #f0f8ff; padding: 10px; border-radius: 5px; font-size: 14px;\">\n",
    "  <b>Key Assumptions</b><br>\n",
    "  The data points \\( (\\mathbf{x}_i, y_i) \\) are drawn from some (unknown) distribution \\( \\mathcal{P}(X, Y) \\). <br>\n",
    "  \\( (\\mathbf{x}_i, y_i) \\sim \\mathcal{P} \\) <br>\n",
    "  <b>Examples:</b>\n",
    "  <ul>\n",
    "    <li>We collect MRI scans of people, resulting in a distribution of MRI scans. This distribution is <b>unknown</b> (some unknown distribution from mother nature).</li>\n",
    "    <li>Collecting pictures of people.</li>\n",
    "  </ul>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "The data can be either i.i.d or non-i.i.d <br>\n",
    "<div style=\"background-color: #dfffd6; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "  <table style=\"width: 100%; border-collapse: collapse; text-align: left; background-color: #dfffd6;\">\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th style=\"border-bottom: 2px solid #ddd; padding: 8px; font-weight: bold;\">i.i.d. Data</th>\n",
    "        <th style=\"border-bottom: 2px solid #ddd; padding: 8px; font-weight: bold;\">Non-i.i.d. Data</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Data points are independent and identically distributed.<br><br>(x, y are all drawn from the same distribution P, and knowing one data point will not tell us anything about the other data points)</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Data points exhibit dependencies or are not identically distributed.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Each observation is independent of all others.</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Observations may be dependent on each other (e.g., temporal, spatial).</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">All observations are drawn from the same probability distribution.</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Observations may come from different distributions or exhibit structured variation.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Example: Random sampling from a population (e.g., rolling a die, flipping a coin).</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Example: Time series data, spatial data, panel data, network data.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Suitable for simple machine learning models, statistical tests assuming independence.</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Suitable for time series forecasting, spatial analysis, hierarchical models.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px;\">Assumes no interaction or correlation between observations.</td>\n",
    "        <td style=\"padding: 8px;\">Assumes correlation, dependence, or structure within the data.</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "</div>\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Examples of Label Spaces:\n",
    "\n",
    "<div style=\"background-color: #fffacd; border: 1px solid #ccc; padding: 10px; border-radius: 5px;\">\n",
    "  <table style=\"width: 100%; border-collapse: collapse; text-align: left; background-color: #fffacd;\">\n",
    "    <thead>\n",
    "      <tr>\n",
    "        <th style=\"border-bottom: 2px solid #ddd; padding: 8px; font-weight: bold;\">Type</th>\n",
    "        <th style=\"border-bottom: 2px solid #ddd; padding: 8px; font-weight: bold;\">Label Space</th>\n",
    "        <th style=\"border-bottom: 2px solid #ddd; padding: 8px; font-weight: bold;\">Example</th>\n",
    "      </tr>\n",
    "    </thead>\n",
    "    <tbody>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Binary Classification</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">$\\mathcal{C} = \\{0, 1\\}$ or $\\{-1, +1\\}$</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Spam Filtering: spam = $+1$, not = $-1$</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Multi-Class Classification</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">$\\mathcal{C} = \\{1, 2, \\ldots, K\\}$</td>\n",
    "        <td style=\"padding: 8px; border-bottom: 1px solid #ddd;\">Face Classification: 1 = \"Obama\", 2 = \"Bush\", etc.</td>\n",
    "      </tr>\n",
    "      <tr>\n",
    "        <td style=\"padding: 8px;\">Regression</td>\n",
    "        <td style=\"padding: 8px;\">$\\mathcal{C} = \\mathbb{R}$</td>\n",
    "        <td style=\"padding: 8px;\">Predict temperature or person's height</td>\n",
    "      </tr>\n",
    "    </tbody>\n",
    "  </table>\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "Examples of Feature Vectors:\n",
    "\n",
    "                                        |\n",
    "\n",
    "---\n",
    "| **Type**                | **Representation**                                                                                                         | **Features**                                                                                                      | **Examples**                                                                                           | **Concept Used**                                                                                      |\n",
    "|-------------------------|-----------------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|--------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------|\n",
    "| **Patient Data (Hospital)** | $\\mathbf{x}_i = \\begin{bmatrix} x^1_i \\\\ x^2_i \\\\ \\vdots \\\\ x^d_i \\end{bmatrix}$                                           | $x^1_i$: gender  <br> $x^2_i$: height (cm)  <br> $x^3_i$: age (years)                                              | $\\mathbf{x}_i = \\begin{bmatrix} 1 \\\\ 62 \\\\ 183 \\\\ \\vdots \\end{bmatrix}$ <br> <br> (e.g., male (Yes/No), 62 years, 183 cm)  | Structured feature representation for numerical and categorical patient data.                          |\n",
    "| **Text Documents**       | $\\mathbf{x}_i = \\begin{bmatrix} x^1_i \\\\ x^2_i \\\\ \\vdots \\\\ x^d_i \\end{bmatrix}$ <br> <br> $\\mathbf{x}_i \\in \\mathbb{R}^d$, <br><br>  where $d$ is the number of words in the English language. | $x^\\alpha_i$: occurrences of the $\\alpha$-th word in the dictionary  <br> (e.g., term frequencies)                | $\\mathbf{x}_i = \\begin{bmatrix} \\vdots \\\\ 7 \\\\ \\vdots \\\\ 0 \\end{bmatrix}$ <br> <br> (e.g., \"ant\": 7, \"zebra\": 0 (ant frequency of occurrence (occured 7 times) , and zebra freq. of occ.=0)) | <b>Bag of Words (BoW)</b>: Represents text as a fixed-length vector based on word frequency in a predefined vocabulary. **Only word frequency is considered; word order is ignored.** |\n",
    "| **Images**               | $\\mathbf{x}_i = \\begin{bmatrix} x^1_i \\\\ x^2_i \\\\ \\vdots \\\\ x^{3k}_i \\end{bmatrix}$                                         | $x^{3j-2}_i$: Red value of the $j$-th pixel  <br> $x^{3j-1}_i$: Green value of the $j$-th pixel  <br> $x^{3j}_i$: Blue value of the $j$-th pixel | $\\mathbf{x}_i = \\begin{bmatrix} R_1 \\\\ G_1 \\\\ B_1 \\\\ R_2 \\\\ G_2 \\\\ B_2 \\\\ \\vdots \\end{bmatrix}$<br> <br>  (e.g., RGB values for pixels) | Pixel intensity representation for image data.                                                         |\n",
    "\n",
    "---\n",
    "<b> Loss Functions  :</b>\n",
    "\n",
    "There are typically two steps involved in learning a hypothesis function $h()$. <br><br>First, we select the type of machine learning algorithm that we think is appropriate for this particular learning problem. This defines the hypothesis class $\\mathcal{H}$, i.e., the set of functions we can possibly learn. The second step is to find the best function within this class, $h \\in \\mathcal{H}$. <br><br>This second step is the actual learning process and often, but not always, involves an optimization problem. Essentially, we try to find a function $h$ within the hypothesis class that makes the fewest mistakes within our training data. (If there is not a single function, we typically try to choose the \"simplest\" by some notion of simplicity - but we will cover this in more detail in a later class.)\n",
    "\n",
    "<b> How can we find the best function? </b> <br>For this, we need some way to evaluate what it means for one function to be better than another. This is where the loss function (also called the risk function) comes in. A loss function evaluates a hypothesis $h \\in \\mathcal{H}$ on our training data and tells us how bad it is. The higher the loss, the worse it is. A loss of zero means it makes perfect predictions. It is common practice to normalize the loss by the total number of training samples, $n$, so that the output can be interpreted as the average loss per sample (and is independent of $n$).\n",
    "\n",
    "Examples:\n",
    "\n",
    "| **Loss Function**         | **Description**                                                                                             | **Mathematical Formula**                                                                                                                                                               | **Explanation in Colloquial English**                                                                                                                                                 | **Use Cases** |\n",
    "|---------------------------|-------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|---------------|\n",
    "| **Zero-One Loss**          | The simplest loss function is the zero-one loss. It literally counts how many mistakes a hypothesis function $h$ makes on the training set. For every single example, it suffers a loss of 1 if it is mispredicted, and 0 otherwise. The normalized zero-one loss returns the fraction of misclassified training samples, also often referred to as the training error. The zero-one loss is often used to evaluate classifiers in multi-class/binary classification settings but rarely useful to guide optimization procedures because the function is non-differentiable and non-continuous. | $$ \\mathcal{L}_{0/1}(h) = \\frac{1}{n} \\sum_{i=1}^n \\delta\\left( h(\\mathbf{x}_i) \\neq y_i \\right), \\quad \\text{where} \\quad \\delta\\left( a \\right) = \\begin{cases} 1, & \\text{if } h(\\mathbf{x}_i) \\neq y_i \\\\ 0, & \\text{otherwise} \\end{cases} $$ | This loss function returns the error rate on this data set $D$. For every example that the classifier misclassifies (i.e., gets wrong), a loss of 1 is suffered, whereas correctly classified samples lead to 0 loss. | Used in classification tasks, especially when the goal is simply to count misclassifications, such as in binary or multi-class classification problems. This loss is simple but not differentiable, which makes it difficult to optimize directly. |\n",
    "| **Squared Loss**           | The squared loss function is typically used in regression settings. It iterates over all training samples and suffers the loss $(h(\\mathbf{x}_i) - y_i)^2$. The squaring has two effects: 1., the loss suffered is always nonnegative; 2., the loss suffered grows quadratically with the absolute mispredicted amount. The latter property encourages no predictions to be really far off (or the penalty would be so large that a different hypothesis function is likely better suited). On the flip side, if a prediction is very close to be correct, the square will be tiny and little attention will be given to that example to obtain zero error. For example, if $|h(\\mathbf{x}_i) - y_i| = 0.001$ the squared loss will be even smaller, $0.000001$, and will likely never be fully corrected. If, given an input $\\mathbf{x}$, the label $y$ is probabilistic according to some distribution $P(y|\\mathbf{x})$ then the optimal prediction to minimize the squared loss is to predict the expected value, i.e. $h(\\mathbf{x}) = \\mathbb{E}_{P(y|\\mathbf{x})}[y]$. | $$ \\mathcal{L}_\\text{sq}(h) = \\frac{1}{n} \\sum_{i=1}^n (h(\\mathbf{x}_i) - y_i)^2 $$ | The squaring has two effects: first, the loss is always non-negative, and second, the penalty increases quadratically as the error grows. This property is useful because it discourages large mispredictions and focuses on getting those predictions right. | Commonly used in regression tasks such as predicting house prices or temperatures. Squaring the error is beneficial as it focuses on minimizing larger errors, which often leads to a better fit and smoother predictions. |\n",
    "| **Absolute Loss**          | Similar to the squared loss, the absolute loss function is also typically used in regression settings. It suffers the penalties $|h(\\mathbf{x}_i) - y_i|$. Because the suffered loss grows linearly with the mispredictions it is more suitable for noisy data (when some mispredictions are unavoidable and shouldnâ€™t dominate the loss). If, given an input $\\mathbf{x}$, the label $y$ is probabilistic according to some distribution $P(y|\\mathbf{x})$ then the optimal prediction to minimize the absolute loss is to predict the median value, i.e. $h(\\mathbf{x}) = \\text{MEDIAN}_{P(y|\\mathbf{x})}[y]$. | $$ \\mathcal{L}_\\text{abs}(h) = \\frac{1}{n} \\sum_{i=1}^n |h(\\mathbf{x}_i) - y_i| $$ | Because the loss grows linearly with mispredictions, it doesnâ€™t penalize large errors as much as squared loss. Itâ€™s more robust in situations where there is noisy data or when mispredictions are unavoidable. | Used in regression when there is noise in the data and you want to avoid letting extreme outliers unduly affect the model, such as in financial predictions or robust modeling. |\n",
    "| **Logarithmic Loss**       | Used for binary classification problems, evaluates how well the predicted probabilities match the true labels. | $$ \\mathcal{L}_\\text{log}(h) = -\\frac{1}{n} \\sum_{i=1}^n \\left( y_i \\log(h(\\mathbf{x}_i)) + (1 - y_i) \\log(1 - h(\\mathbf{x}_i)) \\right) $$                                            | This formula is used when the output is a probability, as in binary classification. It penalizes predictions based on how far off the predicted probability is from the actual class label. | Commonly used in binary classification tasks such as spam detection, medical diagnoses, and other tasks involving probability-based predictions. Logarithmic loss is effective because it maximizes the likelihood of the correct class, and thus works well when predicting probabilities rather than hard labels. |\n",
    "| **Hinge Loss**             | Used for classification tasks, particularly with support vector machines, penalizes misclassifications and allows for margin of error. | $$ \\mathcal{L}_\\text{hinge}(h) = \\frac{1}{n} \\sum_{i=1}^n \\max(0, 1 - y_i h(\\mathbf{x}_i)) $$                                        | The hinge loss is commonly used in classification models like support vector machines. It penalizes predictions that are on the wrong side of the decision boundary, but allows for some margin of error. | Used in classification tasks, particularly with support vector machines (SVMs) for binary or multi-class classification, such as text classification or image classification. Hinge loss is useful because it enforces a margin of error, promoting a larger gap between classes and improving generalization. |\n",
    "<br><br>\n",
    "--- \n",
    "\n",
    "\n",
    "<div style=\"border: 1px solid #ff0000; background-color: #ffe5e5; padding: 10px; border-radius: 5px; font-size: 14px;\">\n",
    "<b>Objective of Supervised Learning:</b><br>\n",
    "Use the training data to learn a function $h$ that goes from $\\mathbf{x}_i$ to $\\mathbf{y}_i$. <br><br>\n",
    "Ultimately, we aim to learn a function $h$ such that for a new pair $(\\mathbf{x}, y) \\sim \\mathcal{P}$: <br>\n",
    "$$h(\\mathbf{x}) = y$$<br>\n",
    "with high probability (or $h(\\mathbf{x}) \\approx y$).\n",
    "</div>\n",
    "\n",
    "<br><br>\n",
    "| **Dense Feature Vector**                                                                                          | **Sparse Feature Vector**                                                                                          |\n",
    "|-------------------------------------------------------------------------------------------------------------------|-------------------------------------------------------------------------------------------------------------------|\n",
    "| Most of the elements have non-zero or meaningful values.                                                          | Most of the elements are zero, with only a few non-zero values.                                                   |\n",
    "| Example:                                                                                                          | Example:                                                                                                          |\n",
    "| $$\\mathbf{x} = \\begin{bmatrix} 0.12 \\\\ 0.34 \\\\ 0.67 \\\\ 0.89 \\\\ \\vdots \\\\ 0.45 \\end{bmatrix}$$                     | $$\\mathbf{x} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 3 \\\\ 0 \\\\ 0 \\\\ 1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{bmatrix}$$                     |\n",
    "| Image pixels (e.g., from MNIST dataset) where almost all pixel values contribute meaningfully.                    | Bag-of-words representation for text where non-zero values indicate word counts in a high-dimensional space.      |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithms"
   ]
  },
  {
   "attachments": {
    "75f69940-a33d-4205-ac0f-14069dbfbe2f.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![s.png](attachment:75f69940-a33d-4205-ac0f-14069dbfbe2f.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid #4CAF50; border-radius: 8px; padding: 10px; background-color: #e8f5e9; color: #2e7d32;\">\n",
    "<b> Hypothesis classes and No Free Lunch </b> <br><br><br>\n",
    "Before we can find a function <b>$h$</b>, <br> we must specify what type of function it is that we are looking for. It could be an artificial neural network, a decision tree or many other types of classifiers. We call the set of possible functions the <b> Hypothesis class</b>. By specifying the hypothesis class, we are encoding important assumptions about the type of problem we are trying to learn. The <b> No Free Lunch Theorem </b> states that every successful ML algorithm must make assumptions. This also means that there is no single ML algorithm that works for every setting.\n",
    "</div><br><br>\n",
    "\n",
    "$$h  \\in \\mathcal{H}$$<br>\n",
    "$$\\text{where} \\mathcal{H} \\text{is the Hypothesis Class}$$\n",
    "\n",
    "<br>\n",
    "<b> What the M.L Algorithm does(Learning): </b><br> Out of an infinelty many functions that it could learn, it picks the best $h$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid red; background-color: #f8d7da; padding: 10px; border-radius: 5px;\">\n",
    "    <strong>How to find the optimal $h$?</strong><br>\n",
    "    - Use Loss Functions.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid red; background-color: #f8d7da; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<strong>GENERALIZATION :</strong>\n",
    "\n",
    "We aim to find a function $h$ from a set of all functions $\\mathcal{H}$, such that:\n",
    "\n",
    "<p style=\"color:blue;\">$h \\in \\mathcal{H} \\quad \\text{such that } \\forall (x, y) \\sim \\mathcal{P}, \\; h(x) \\approx y$</p>\n",
    "\n",
    "This means we want a function $h$ such that any $x$ and $y$ drawn from the distribution $\\mathcal{P}$ satisfies $h(x) \\approx y$.\n",
    "\n",
    "---\n",
    "\n",
    "Given our function $h$, what loss would we expect to find if we apply it to a new dataset, assuming the data is from the same distribution?\n",
    "\n",
    "<p style=\"color:purple;\">$\\mathbb{E}_{(x, y) \\sim \\mathcal{P}} \\big[ L(h; (x, y)) \\big]$</p>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"border: 2px solid orange; background-color: #fff3cd; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Important Concept:</strong>\n",
    "\n",
    "Ideally, we would like to minimize the expected loss:\n",
    "\n",
    "<p style=\"color:purple;\">$\\mathbb{E}_{(x, y) \\sim \\mathcal{P}} \\big[ L(h; (x, y)) \\big]$</p>\n",
    "\n",
    "However, we **do not have access** to the true distribution $\\mathcal{P}$, which governs the relationship between inputs $x$ and outputs $y$.  \n",
    "Instead, we work with a finite dataset sampled from $\\mathcal{P}$. This is why **generalization** is critical in machine learning:  \n",
    "We need to ensure that the function $h$ performs well not just on the training data, but also on unseen data that comes from the same distribution $\\mathcal{P}$.\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"border: 2px solid green; background-color: #d4edda; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Practical Approach:</strong>\n",
    "\n",
    "Since we cannot compute $\\mathbb{E}_{(x, y) \\sim \\mathcal{P}} \\big[ L(h; (x, y)) \\big]$ directly (as we lack access to $\\mathcal{P}$), we estimate it using a **test-train split**.\n",
    "\n",
    "1. **Split the data** into:\n",
    "   - **Training set ($D_{\\text{TR}}$):** Used to train the function $h$.\n",
    "   - **Testing set ($D_{\\text{TE}}$):** Used to evaluate $h$ on unseen data.\n",
    "\n",
    "2. **Compute the empirical average of the loss** on the testing set to approximate the true expected loss:\n",
    "\n",
    "<p style=\"color:blue;\">$\\hat{\\mathbb{E}}_{(x, y) \\in D_{\\text{TE}}} \\big[ L(h; (x, y)) \\big]$</p>\n",
    "\n",
    "This empirical loss on the testing set serves as an estimate of the generalization error.  \n",
    "By testing on unseen data, we simulate the performance of $h$ on the true distribution $\\mathcal{P}$.\n",
    "\n",
    "</div>\n",
    "\n",
    "---\n",
    "\n",
    "**Explanation of Terms in the Expectation Equation:**\n",
    "\n",
    "1. **$\\mathbb{E}$:**\n",
    "   - **Math Definition:** The expectation operator, which calculates the average value of a random variable under a probability distribution.\n",
    "   - **Colloquial English:** Think of it as the \"average\" or \"expected\" value when you sample data points repeatedly from the same distribution.\n",
    "\n",
    "2. **$(x, y) \\sim \\mathcal{P}$:**\n",
    "   - **Math Definition:** The pair of data points $(x, y)$ are sampled from the probability distribution $\\mathcal{P}$.\n",
    "   - **Colloquial English:** This means that the inputs $x$ (features) and outputs $y$ (labels) are generated by the same underlying process or pattern (distribution) $\\mathcal{P}$.\n",
    "\n",
    "3. **$L(h; (x, y))$:**\n",
    "   - **Math Definition:** The loss function $L$ measures how far off the prediction $h(x)$ is from the actual value $y$, for the function $h$ applied to input $x$.\n",
    "   - **Colloquial English:** This is how much the prediction made by the model $h$ \"misses the mark\" when compared to the true answer $y$. It tells us how bad the prediction is for one data point.\n",
    "\n",
    "4. **$\\mathbb{E}_{(x, y) \\sim \\mathcal{P}} \\big[ L(h; (x, y)) \\big]$:**\n",
    "   - **Math Definition:** The expected loss is the average value of the loss function $L(h; (x, y))$, calculated over all possible data points $(x, y)$ sampled from the distribution $\\mathcal{P}$.\n",
    "   - **Colloquial English:** This is the average error you'd expect the model $h$ to make if you tested it on an infinite number of new data points drawn from the same underlying process $\\mathcal{P}$.\n",
    "\n",
    "**Why is this Important?**  \n",
    "This equation tells us how good a model $h$ is in the long run, not just on the training data. Since we don't know $\\mathcal{P}$ (the true distribution), we approximate this using finite datasets and assume they come from $\\mathcal{P}$.\n",
    "\n",
    "---\n",
    "\n",
    "The best function $h$ will find the solution by minimizing the loss:\n",
    "\n",
    "<p style=\"color:green;\">$h = \\arg\\min_{h \\in \\mathcal{H}} L(h)$</p>\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid green; background-color: #d4edda; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Estimating Generalization Error:</strong>\n",
    "\n",
    "Since we cannot compute $\\mathbb{E}_{(x, y) \\sim \\mathcal{P}} \\big[ L(h; (x, y)) \\big]$ directly (as we lack access to $\\mathcal{P}$), we estimate it using a **test-train split**.\n",
    "\n",
    "1. **Split the data** into:\n",
    "   - **Training set ($D_{\\text{TR}}$):** Used to train the function $h$.\n",
    "   - **Testing set ($D_{\\text{TE}}$):** Used to evaluate $h$ on unseen data.\n",
    "\n",
    "2. **Compute the empirical average of the loss** on the testing set to approximate the true expected loss:\n",
    "\n",
    "<p style=\"color:blue;\">$\\hat{\\mathbb{E}}_{(x, y) \\in D_{\\text{TE}}} \\big[ L(h; (x, y)) \\big]$</p>\n",
    "\n",
    "This empirical loss on the testing set serves as an estimate of the generalization error.  \n",
    "By testing on unseen data, we simulate the performance of $h$ on the true distribution $\\mathcal{P}$.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid red; background-color: #f8d7da; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<strong>Estimating Generalization Error in Machine Learning:</strong>\n",
    "\n",
    "In machine learning, the **generalization error** measures how well a model performs on unseen data. Since we cannot compute the true expected loss directly (as we lack access to the true data distribution $\\mathcal{P}$), we estimate it using finite datasets.\n",
    "\n",
    "---\n",
    "\n",
    "<div style=\"border: 2px solid green; background-color: #d4edda; padding: 10px; border-radius: 5px;\">\n",
    "<strong>Practical Approach to Estimate Generalization Error:</strong>\n",
    "\n",
    "1. **Split the Data:**\n",
    "   - Divide the dataset $D$ into:\n",
    "     - **Training set ($D_{\\text{TR}}$):** Used to train the model $h$.\n",
    "     - **Testing set ($D_{\\text{TE}}$):** Used to evaluate the model on unseen data.\n",
    "\n",
    "2. **Train the Model:** Use $D_{\\text{TR}}$ to train the function $h$ by minimizing the training loss.\n",
    "\n",
    "3. **Evaluate on Testing Set:** Compute the average loss on $D_{\\text{TE}}$ to estimate the generalization error:\n",
    "\n",
    "   <p style=\"color:blue;\">$\\hat{\\mathbb{E}}_{(x, y) \\in D_{\\text{TE}}} \\big[ L(h; (x, y)) \\big]$</p>\n",
    "\n",
    "   This represents the empirical generalization error based on the test data.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Considerations:**\n",
    "\n",
    "- **Overfitting:** A model may perform well on $D_{\\text{TR}}$ but poorly on $D_{\\text{TE}}$. This indicates poor generalization.\n",
    "- **Cross-Validation:** To get a more reliable estimate of the generalization error, use $k$-fold cross-validation. Split the data into $k$ subsets and evaluate the model on multiple testing sets.\n",
    "\n",
    "**Equation for Cross-Validation Estimate:**\n",
    "<p style=\"color:purple;\">$\\hat{\\mathbb{E}} \\big[ L(h; (x, y)) \\big] = \\frac{1}{k} \\sum_{i=1}^k \\hat{\\mathbb{E}}_{(x, y) \\in D_{\\text{TE}, i}} \\big[ L(h; (x, y)) \\big]$</p>\n",
    "\n",
    "- Here, $D_{\\text{TE}, i}$ represents the testing set for the $i$-th fold, and $k$ is the number of folds.\n",
    "\n",
    "4. **Bias-Variance Tradeoff:** The generalization error is affected by:\n",
    "   - **Bias:** Error due to incorrect assumptions in the learning algorithm.\n",
    "   - **Variance:** Error due to sensitivity to small fluctuations in the training set.\n",
    "   - The goal is to balance bias and variance to minimize the generalization error.\n",
    "\n",
    "5. **Model Selection:** Use the validation set $D_{\\text{VA}}$ to tune hyperparameters and select the best model. Afterward, evaluate the final model on $D_{\\text{TE}}$ to estimate the true generalization error.\n",
    "\n",
    "---\n",
    "\n",
    "**Why Generalization Error Matters:**  \n",
    "The generalization error reflects how well a model can predict outputs for unseen data. Minimizing this error is the ultimate goal of machine learning because it ensures the model's performance is not limited to just the training dataset.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"border: 2px solid red; background-color: #f8d7da; padding: 10px; border-radius: 5px;\">\n",
    "\n",
    "<strong>GENERALIZATION :</strong>\n",
    "\n",
    "Given a loss function, we can attempt to find the function $h$ that minimizes the loss:\n",
    "\n",
    "<p style=\"color:blue;\">$$\n",
    "h = \\arg\\min_{h \\in \\mathcal{H}} \\mathcal{L}(h)\n",
    "$$</p>\n",
    "\n",
    "A significant part of machine learning focuses on the question: **How do we minimize this efficiently?**\n",
    "\n",
    "If you find a function $h(\\cdot)$ with low loss on your data $D$, how do you know whether it will still perform well on examples not in $D$?\n",
    "\n",
    "Bad example: **\"memorizer\"** $h(\\cdot)$\n",
    "\n",
    "<p style=\"color:red;\">$$\n",
    "h(x) =\n",
    "\\begin{cases} \n",
    "y_i, & \\text{if } \\exists (x_i, y_i) \\in D \\text{ such that } \\mathbf{x} = \\mathbf{x}_i, \\\\\n",
    "0, & \\text{otherwise.}\n",
    "\\end{cases}\n",
    "$$</p>\n",
    "\n",
    "For this $h(\\cdot)$, we get **0% error** on the training data $D$, but it performs poorly with samples not in $D$, i.e., this function suffers from **overfitting**.\n",
    "\n",
    "---\n",
    "\n",
    "Train / Test splits:\n",
    "\n",
    "To address the overfitting issue, we usually split $D$ into three subsets: \n",
    "\n",
    "- $D_{\\text{TR}}$: the training data,  \n",
    "- $D_{\\text{VA}}$: the validation data, and  \n",
    "- $D_{\\text{TE}}$: the test data.  \n",
    "\n",
    "Typically, these are split in proportions of 80%, 10%, and 10%. We choose $h(\\cdot)$ based on $D_{\\text{TR}}$ and evaluate $h(\\cdot)$ on $D_{\\text{TE}}$.\n",
    "\n",
    "**Quiz:** Why do we need $D_{\\text{VA}}$?\n",
    "\n",
    "<p style=\"color:purple;\">$D_{\\text{VA}}$ is used to check whether the $h(\\cdot)$ obtained from $D_{\\text{TR}}$ suffers from overfitting.  \n",
    "If the loss on $D_{\\text{VA}}$ is too large, $h(\\cdot)$ will be revised based on $D_{\\text{TR}}$ and validated again on $D_{\\text{VA}}$.  \n",
    "This iterative process ensures low loss on $D_{\\text{VA}}$.</p>\n",
    "\n",
    "There is a trade-off between the sizes of $D_{\\text{TR}}$ and $D_{\\text{VA}}$:  \n",
    "- Larger $D_{\\text{TR}}$ improves training results.  \n",
    "- Larger $D_{\\text{VA}}$ makes validation more reliable (less noisy).\n",
    "\n",
    "---\n",
    "\n",
    "How to Split the Data?\n",
    "\n",
    "It is critical to carefully split the data into Train, Validation, and Test sets. The test set must simulate a real test scenario. For instance:\n",
    "\n",
    "- If training an email spam filter, train the system on past data to predict whether future emails are spam.  \n",
    "- Ensure splits are made temporally if the data has a temporal component.  \n",
    "- If no temporal component exists, split the data **uniformly at random**.\n",
    "\n",
    "**Avoid improper splits:**\n",
    "- Never split alphabetically or by feature values.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Guidelines:**\n",
    "\n",
    "1. **By time:** If the data is temporally collected, split train/test temporally.  \n",
    "2. **Uniformly at random:** Only applicable if data is **i.i.d.**  \n",
    "\n",
    "The **test error (testing loss)** approximates the true generalization error/loss.\n",
    "\n",
    "---\n",
    "\n",
    "Putting everything together:\n",
    "\n",
    "We train our classifier by minimizing the training loss:\n",
    "\n",
    "<p style=\"color:blue;\">$$\n",
    "\\text{Learning: } h^*(\\cdot) = \\arg\\min_{h(\\cdot) \\in \\mathcal{H}} \\frac{1}{|D_{\\text{TR}}|} \\sum_{(x, y) \\in D_{\\text{TR}}} \\ell(x, y | h(\\cdot)),\n",
    "$$</p>\n",
    "\n",
    "where $\\mathcal{H}$ represents the set of all possible classifiers $h(\\cdot)$. We aim to find a hypothesis $h$ that performs well on known/past data.\n",
    "\n",
    "The classifier is evaluated on the testing loss:\n",
    "\n",
    "<p style=\"color:green;\">$$\n",
    "\\text{Evaluation: } \\epsilon_{\\text{TE}} = \\frac{1}{|D_{\\text{TE}}|} \\sum_{(x, y) \\in D_{\\text{TE}}} \\ell(x, y | h^*(\\cdot)).\n",
    "$$</p>\n",
    "\n",
    "If the samples are i.i.d. from the same distribution $\\mathcal{P}$, the testing loss is an unbiased estimator of the true generalization loss:\n",
    "\n",
    "<p style=\"color:purple;\">$$\n",
    "\\text{Generalization: } \\epsilon = \\mathbb{E}_{(x, y) \\sim \\mathcal{P}}[\\ell(x, y | h^*(\\cdot))].\n",
    "$$</p>\n",
    "\n",
    "**Quiz:** Why does $\\epsilon_{\\text{TE}} \\to \\epsilon$ as $|D_{\\text{TE}}| \\to +\\infty$?  \n",
    "\n",
    "This follows from the **weak law of large numbers**, stating that the empirical average of data drawn from a distribution converges to its mean.\n",
    "\n",
    "---\n",
    "\n",
    "**Key Insight:**\n",
    "- **No Free Lunch:** Machine learning algorithms rely on assumptions about which hypothesis class $\\mathcal{H}$ to choose.  \n",
    "- These assumptions depend on the data and the underlying distribution $\\mathcal{P}$.  \n",
    "- No single hypothesis class $\\mathcal{H}$ works for all problems.\n",
    "\n",
    "---\n",
    "\n",
    "Example:\n",
    "\n",
    "Given points $(x_1, y_1) = (1, 1), (x_2, y_2) = (2, 2), (x_3, y_3) = (3, 3), (x_4, y_4) = (4, 4), (x_5, y_5) = (5, 5)$,  \n",
    "**Question:** What is $y$ if $x = 2.5$?\n",
    "\n",
    "**Answer:** Impossible to know without assumptions.  \n",
    "The common assumption is that the function to be approximated is **locally smooth**.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"font-family: Arial; font-size: 14px; line-height: 1.5;\">\n",
    "<b style=\"color: darkblue;\">Key Idea:</b>  \n",
    "Proper data splitting is essential in machine learning to evaluate models without bias. The dataset is divided into three parts: training, validation, and test sets. Careful splitting ensures generalizable results, avoiding pitfalls such as data leakage and overfitting.\n",
    "\n",
    "---\n",
    "\n",
    "<b style=\"color: green;\">Steps for Data Splitting:</b>  \n",
    "1. <b>Training Set (D<sub>train</sub>):</b> Used for model training. The model learns patterns and relationships between features and labels.  \n",
    "2. <b>Validation Set (D<sub>val</sub>):</b> Helps in model selection and hyperparameter tuning, providing feedback for optimization.  \n",
    "3. <b>Test Set (D<sub>test</sub>):</b> Offers an unbiased estimate of the model's performance on unseen data.  \n",
    "\n",
    "---\n",
    "\n",
    "<b style=\"color: crimson;\">Important Principles for Splitting with Scientific Examples:</b>  \n",
    "\n",
    "- <b>Temporal Data:</b> When data has a time-dependent structure (e.g., spam filtering, stock prices), it is crucial to split by time to avoid future information leaking into training.  \n",
    "  - <b>Scientific Depth:</b> In spam filtering, emails often appear in clusters over time as spammers send the same message to multiple users. A random split might place nearly identical emails in both the training and test sets, artificially inflating performance metrics. To address this, split based on the temporal order of data collection, ensuring the model learns from past data to predict future eventsâ€”a closer reflection of real-world deployment conditions.\n",
    "\n",
    "- <b>i.i.d. Data:</b> For datasets assumed to be independent and identically distributed, random splitting is appropriate. However, ensure the splitting method does not introduce bias inadvertently.  \n",
    "  - <b>Scientific Depth:</b> For example, if data points are stored sequentially by label (e.g., all samples of class \"1\" followed by class \"0\"), a naive split could result in one class being entirely in the test set. This would lead to a biased evaluation where the model has no exposure to certain classes during training. Random shuffling before splitting ensures all classes are proportionally represented in both sets, adhering to the i.i.d. assumption.\n",
    "\n",
    "- <b>Grouped Data:</b> In datasets with inherent group structures (e.g., patient records, households), ensure entire groups are placed exclusively in training or testing.  \n",
    "  - <b>Scientific Depth:</b> Patient data often includes multiple samples (e.g., MRI scans, blood tests) for the same individual. If such samples are split randomly, the model could indirectly \"learn\" about the test data by memorizing patient-specific patterns from the training set. This results in overestimation of model performance. Assigning entire patients to either training or testing prevents such leakage, ensuring the model generalizes to unseen individuals rather than memorizing intra-group similarities.\n",
    "\n",
    "---\n",
    "\n",
    "<b style=\"color: teal;\">Overfitting on the Test Set:</b>  \n",
    "Repeatedly evaluating multiple models on the test set introduces selection bias, as the final model is implicitly optimized on the test data.  \n",
    "<b style=\"color: crimson;\">Solution:</b>  \n",
    "Introduce a validation set to guide model selection and reserve the test set for a single, final evaluation of generalization error.\n",
    "\n",
    "<b>Scientific Example:</b>  \n",
    "Consider testing a face recognition model on a dataset where the test set consists of 100 faces, and the model initially misclassifies 5. If the model is iteratively fine-tuned to correct these 5 misclassifications, its apparent error rate drops to 0%. However, this improvement is often due to overfitting on the specific test set, not genuine generalization. By introducing a validation set, the model can be refined without compromising the test set's role as an unbiased estimator.\n",
    "\n",
    "---\n",
    "\n",
    "<b style=\"color: darkorange;\">Additional Notes:</b>  \n",
    "- <b>Split Ratios:</b> A common split is 80% training, 10% validation, and 10% test.  \n",
    "- <b>Small Datasets:</b> Techniques like leave-one-out cross-validation are useful for datasets with limited samples.  \n",
    "- <b>Variance and Bias:</b> Larger test sets provide lower variance in error estimates but reduce the amount of data available for training.\n",
    "\n",
    "<b>Scientific Example:</b>  \n",
    "In small datasets, such as those involving rare diseases, every sample is valuable. Leave-one-out cross-validation ensures the model is trained on as much data as possible while providing an unbiased error estimate. For example, in an MRI-based diagnostic study with only 11 patients, the model can be trained on 10 patients and tested on the remaining one, repeating the process for all patients.\n",
    "\n",
    "---\n",
    "\n",
    "<b style=\"color: darkblue;\">Key Takeaway:</b>  \n",
    "Machine learning requires assumptions about the data, such as independence, temporal structure, or group-level organization. The success of an algorithm depends on its ability to leverage these assumptions effectively. No single algorithm works best for all scenarios, so understanding data properties is crucial for selecting the right model.\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
